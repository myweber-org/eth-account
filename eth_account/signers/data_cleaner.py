import re
import string

def clean_text(text, remove_punctuation=True, lowercase=True, remove_numbers=False):
    """
    Clean and normalize a given text string.

    Args:
        text (str): The input text to clean.
        remove_punctuation (bool): If True, remove all punctuation.
        lowercase (bool): If True, convert text to lowercase.
        remove_numbers (bool): If True, remove all digits.

    Returns:
        str: The cleaned text.
    """
    if not isinstance(text, str):
        return ""

    cleaned = text.strip()

    if remove_numbers:
        cleaned = re.sub(r'\d+', '', cleaned)

    if remove_punctuation:
        translator = str.maketrans('', '', string.punctuation)
        cleaned = cleaned.translate(translator)

    if lowercase:
        cleaned = cleaned.lower()

    cleaned = re.sub(r'\s+', ' ', cleaned)

    return cleaned

def tokenize_text(text, delimiter=' '):
    """
    Split text into tokens based on a delimiter.

    Args:
        text (str): The input text.
        delimiter (str): The delimiter to split on.

    Returns:
        list: A list of tokens.
    """
    cleaned = clean_text(text)
    if not cleaned:
        return []
    return cleaned.split(delimiter)

if __name__ == "__main__":
    sample_text = "Hello, World! This is a TEST. 12345"
    print(f"Original: {sample_text}")
    print(f"Cleaned: {clean_text(sample_text)}")
    print(f"Tokens: {tokenize_text(sample_text)}")import numpy as np
import pandas as pd
from scipy import stats

def remove_outliers_iqr(data, column, multiplier=1.5):
    """
    Remove outliers using IQR method.
    """
    if column not in data.columns:
        raise ValueError(f"Column '{column}' not found in DataFrame")
    
    Q1 = data[column].quantile(0.25)
    Q3 = data[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - multiplier * IQR
    upper_bound = Q3 + multiplier * IQR
    
    filtered_data = data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]
    return filtered_data

def remove_outliers_zscore(data, column, threshold=3):
    """
    Remove outliers using Z-score method.
    """
    if column not in data.columns:
        raise ValueError(f"Column '{column}' not found in DataFrame")
    
    z_scores = np.abs(stats.zscore(data[column]))
    filtered_data = data[z_scores < threshold]
    return filtered_data

def normalize_minmax(data, column):
    """
    Normalize data using Min-Max scaling.
    """
    if column not in data.columns:
        raise ValueError(f"Column '{column}' not found in DataFrame")
    
    min_val = data[column].min()
    max_val = data[column].max()
    
    if min_val == max_val:
        return data[column].apply(lambda x: 0.5)
    
    normalized = (data[column] - min_val) / (max_val - min_val)
    return normalized

def normalize_zscore(data, column):
    """
    Normalize data using Z-score standardization.
    """
    if column not in data.columns:
        raise ValueError(f"Column '{column}' not found in DataFrame")
    
    mean_val = data[column].mean()
    std_val = data[column].std()
    
    if std_val == 0:
        return data[column].apply(lambda x: 0)
    
    standardized = (data[column] - mean_val) / std_val
    return standardized

def clean_dataset(df, numeric_columns=None, outlier_method='iqr', normalize_method='minmax'):
    """
    Comprehensive data cleaning pipeline.
    """
    if numeric_columns is None:
        numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()
    
    cleaned_df = df.copy()
    
    for col in numeric_columns:
        if col not in df.columns:
            continue
            
        if outlier_method == 'iqr':
            cleaned_df = remove_outliers_iqr(cleaned_df, col)
        elif outlier_method == 'zscore':
            cleaned_df = remove_outliers_zscore(cleaned_df, col)
        
        if normalize_method == 'minmax':
            cleaned_df[col] = normalize_minmax(cleaned_df, col)
        elif normalize_method == 'zscore':
            cleaned_df[col] = normalize_zscore(cleaned_df, col)
    
    return cleaned_df

def validate_data(df, required_columns=None, allow_nan=False):
    """
    Validate data structure and content.
    """
    if required_columns:
        missing_cols = [col for col in required_columns if col not in df.columns]
        if missing_cols:
            raise ValueError(f"Missing required columns: {missing_cols}")
    
    if not allow_nan:
        nan_count = df.isnull().sum().sum()
        if nan_count > 0:
            raise ValueError(f"Data contains {nan_count} NaN values")
    
    return True

def get_data_summary(df):
    """
    Generate comprehensive data summary.
    """
    summary = {
        'shape': df.shape,
        'columns': df.columns.tolist(),
        'dtypes': df.dtypes.to_dict(),
        'missing_values': df.isnull().sum().to_dict(),
        'numeric_summary': df.describe().to_dict() if df.select_dtypes(include=[np.number]).shape[1] > 0 else {}
    }
    return summary